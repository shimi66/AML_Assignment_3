{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d76b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1948c4a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13984\\341421700.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_lines_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnum_lines_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mnum_lines_before\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f = open(\"amazon/Home_and_Kitchen.json\", \"r\")\n",
    "f2 = open(\"amazon/Home_and_Kitchen_8.json\", \"w\")\n",
    "\n",
    "num_lines_before = 0\n",
    "num_lines_after = 0\n",
    "for line in f:\n",
    "    num_lines_before += 1\n",
    "    if hash(line) % 8 == 0:\n",
    "        f2.write(line)\n",
    "        num_lines_after += 1\n",
    "\n",
    "f.close()\n",
    "f2.close()\n",
    "\n",
    "print(num_lines_before)\n",
    "print(num_lines_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"amazon/meta_Home_and_Kitchen.json\", \"r\")\n",
    "\n",
    "print(f.readline())\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8296482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open(\"amazon/Home_and_Kitchen_8.json\", \"r\")\n",
    "f2 = open(\"amazon/Home_and_Kitchen_8_new.txt\", \"w\")\n",
    "\n",
    "# line = f.readline()\n",
    "# line = json.loads(line)\n",
    "\n",
    "# print(type(line['reviewText']))\n",
    "num_lines = 0\n",
    "\n",
    "for line in f:\n",
    "    tmp = json.loads(line)\n",
    "    try:\n",
    "        if len(tmp['reviewText']) > 5:\n",
    "            f2.write(tmp['reviewText'] + \"\\n\")\n",
    "            num_lines += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "f.close()\n",
    "f2.close()\n",
    "\n",
    "print(num_lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f57dfa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Erik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'don', 't', 'use', 'these', 'for', 'their', 'original', 'use', 'and']\n",
      "2864352\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import tokenize\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "with open(\"amazon/Home_and_Kitchen_8_new.txt\", \"r\") as f:\n",
    "    tokenized_texts = [list(tokenize(text)) for text in f]\n",
    "    \n",
    "print(tokenized_texts[0][:10])\n",
    "print(len(tokenized_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b787ebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use', 'original', 'use', 'purchased', 'needed', 'replacements', 'last', 'year', 'never', 'even']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filtered = [[w for w in text if not w.lower() in stops] for text in tokenized_texts]\n",
    "\n",
    "print(filtered[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67082de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['us',\n",
       " 'origin',\n",
       " 'us',\n",
       " 'purchas',\n",
       " 'need',\n",
       " 'replac',\n",
       " 'last',\n",
       " 'year',\n",
       " 'never',\n",
       " 'even']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_texts = [[stemmer.stem(word) for word in text] for text in filtered]\n",
    "\n",
    "stemmed_texts[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2311e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "\n",
    "dictionary = Dictionary(stemmed_texts)\n",
    "# A corpus is a sparse datastore containing the number of times each word appears in each document.\n",
    "corpus = [dictionary.doc2bow(text) for text in stemmed_texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ee1639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us   \tindex: 19\tcount: 3\n",
      "actual   \tindex: 0\tcount: 1\n",
      "even   \tindex: 1\tcount: 1\n",
      "find   \tindex: 2\tcount: 1\n",
      "found   \tindex: 3\tcount: 1\n",
      "immedi   \tindex: 4\tcount: 1\n",
      "internet   \tindex: 5\tcount: 1\n",
      "last   \tindex: 6\tcount: 1\n",
      "less   \tindex: 7\tcount: 1\n",
      "need   \tindex: 8\tcount: 1\n"
     ]
    }
   ],
   "source": [
    "top_words_in_doc_0 = sorted(corpus[0], key=lambda e: e[1], reverse=True)[:10]\n",
    "for word_index, count in top_words_in_doc_0:\n",
    "  print(f'{dictionary[word_index]}   \\tindex: {word_index}\\tcount: {count:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc7514f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2864352\n",
      "123340\n",
      "2864352\n"
     ]
    }
   ],
   "source": [
    "print(len(stemmed_texts))\n",
    "print(len(dictionary))\n",
    "print(len(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c68ee6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models, similarities\n",
    "\n",
    "\n",
    "model = models.LdaMulticore(corpus, id2word=dictionary, num_topics=10, workers=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "316b0b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.018*\"us\" + 0.014*\"cut\" + 0.012*\"love\" + 0.012*\"like\" + 0.010*\"nice\" + 0.010*\"knife\" + 0.009*\"wash\" + 0.009*\"towel\" + 0.008*\"sheet\" + 0.008*\"on\"'), (1, '0.025*\"work\" + 0.020*\"bag\" + 0.016*\"us\" + 0.015*\"great\" + 0.012*\"nice\" + 0.011*\"well\" + 0.010*\"littl\" + 0.010*\"would\" + 0.009*\"like\" + 0.009*\"lid\"'), (2, '0.032*\"look\" + 0.027*\"great\" + 0.020*\"nice\" + 0.014*\"room\" + 0.014*\"work\" + 0.013*\"color\" + 0.013*\"well\" + 0.011*\"like\" + 0.011*\"light\" + 0.010*\"realli\"'), (3, '0.033*\"love\" + 0.023*\"pillow\" + 0.019*\"bed\" + 0.017*\"great\" + 0.016*\"us\" + 0.014*\"perfect\" + 0.011*\"soft\" + 0.011*\"mattress\" + 0.011*\"comfort\" + 0.010*\"like\"'), (4, '0.010*\"top\" + 0.010*\"put\" + 0.010*\"us\" + 0.009*\"on\" + 0.009*\"fit\" + 0.007*\"get\" + 0.007*\"hold\" + 0.007*\"like\" + 0.007*\"small\" + 0.007*\"open\"'), (5, '0.032*\"product\" + 0.025*\"qualiti\" + 0.022*\"good\" + 0.022*\"great\" + 0.018*\"price\" + 0.013*\"arriv\" + 0.012*\"look\" + 0.012*\"would\" + 0.011*\"order\" + 0.011*\"receiv\"'), (6, '0.048*\"us\" + 0.016*\"time\" + 0.014*\"on\" + 0.012*\"wash\" + 0.011*\"make\" + 0.010*\"first\" + 0.009*\"smell\" + 0.008*\"like\" + 0.007*\"plastic\" + 0.007*\"get\"'), (7, '0.045*\"love\" + 0.028*\"on\" + 0.019*\"gift\" + 0.015*\"bought\" + 0.014*\"like\" + 0.012*\"beauti\" + 0.010*\"made\" + 0.010*\"great\" + 0.009*\"look\" + 0.009*\"set\"'), (8, '0.032*\"us\" + 0.021*\"easi\" + 0.019*\"pan\" + 0.019*\"clean\" + 0.018*\"cook\" + 0.013*\"make\" + 0.013*\"great\" + 0.011*\"work\" + 0.010*\"stick\" + 0.009*\"well\"'), (9, '0.021*\"coffe\" + 0.020*\"us\" + 0.017*\"work\" + 0.015*\"water\" + 0.013*\"on\" + 0.011*\"year\" + 0.010*\"time\" + 0.010*\"replac\" + 0.009*\"cup\" + 0.009*\"filter\"')]\n"
     ]
    }
   ],
   "source": [
    "print(model.show_topics(num_topics=10, num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "123206bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  on sheet towel wash knife nice like love cut us\n",
      "1:  lid like would littl well nice great us bag work\n",
      "2:  realli light like well color work room nice great look\n",
      "3:  like comfort mattress soft perfect us great bed pillow love\n",
      "4:  open small like hold get fit on us put top\n",
      "5:  receiv order would look arriv price great good qualiti product\n",
      "6:  get plastic like smell first make wash on time us\n",
      "7:  set look great made beauti like bought gift on love\n",
      "8:  well stick work great make cook clean pan easi us\n",
      "9:  filter cup replac time year on water work us coffe\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for ix in range(10):\n",
    "  top10 = np.argsort(model.get_topics()[ix])[-10:]\n",
    "  print(f'{ix}:  {\" \".join([dictionary[index] for index in top10])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "77f99ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying without stemmed words\n",
    "\n",
    "new_corpus = [dictionary.doc2bow(text) for text in filtered]\n",
    "\n",
    "model = models.LdaMulticore(new_corpus, id2word=dictionary, num_topics=10, workers=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "743151b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  bags food lid bag like get great clean plastic use\n",
      "1:  would nice one fit great together well small room put\n",
      "2:  one use back product return review box would like expected\n",
      "3:  much love got use knife year set old bought one\n",
      "4:  little fast made use great work works beautiful well product\n",
      "5:  wash white picture look pan much use like color love\n",
      "6:  product time works item bed gift size perfect one great\n",
      "7:  product happy really well would great nice good price quality\n",
      "8:  make one mug ice time hot use cup water coffee\n",
      "9:  sleep clock mattress air time night soft one like pillow\n"
     ]
    }
   ],
   "source": [
    "for ix in range(10):\n",
    "  top10 = np.argsort(model.get_topics()[ix])[-10:]\n",
    "  print(f'{ix}:  {\" \".join([dictionary[index] for index in top10])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "443502d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umass:  -2.886518056258612\n",
      "c_v:  0.5577632922393884\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"umass: \", coherence)\n",
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='c_v')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"c_v: \", coherence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb0bc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with less topics\n",
    "\n",
    "model = models.LdaMulticore(new_corpus, id2word=dictionary, num_topics=5, workers=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63a96f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  used back first get new time pillow like would one\n",
      "1:  like price made expected use works good well product great\n",
      "2:  one would good great well price nice like love quality\n",
      "3:  time one coffee cup hot use gift nice great water\n",
      "4:  make little would one bed time mattress like get use\n"
     ]
    }
   ],
   "source": [
    "for ix in range(5):\n",
    "  top10 = np.argsort(model.get_topics()[ix])[-10:]\n",
    "  print(f'{ix}:  {\" \".join([dictionary[index] for index in top10])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b95ea1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umass:  -2.8243309493290667\n",
      "c_v:  0.5208419042954683\n"
     ]
    }
   ],
   "source": [
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"umass: \", coherence)\n",
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='c_v')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"c_v: \", coherence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4f9c7ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"you're\", 'which', 'has', \"don't\", 'having', 'be', \"shouldn't\", \"wasn't\", \"shan't\", 'get', 'y', 'during', 'out', 'few', 'very', 've', 'with', 'we', 'on', 'most', \"isn't\", 'myself', 'how', 'used', \"that'll\", 'once', 'like', 'were', 'll', 'her', 'who', \"doesn't\", \"wouldn't\", 'because', 'that', 'own', 'd', 'up', 'loves', \"mustn't\", 'where', 'for', 'have', 'been', 'from', 'don', 'use', 'down', 'they', 'as', 'theirs', 'he', 'under', 'shan', \"should've\", \"mightn't\", 'ma', 'are', 'all', 're', 'this', 'won', 'or', 'does', 'shouldn', 'his', 'i', 'was', 'haven', 'to', 'if', 'your', 'its', 'a', 'just', 'when', 'ours', 'at', 'more', 'some', 's', 'can', \"needn't\", 'even', 'themselves', 'so', 'through', 'am', 'do', 'about', 'not', 'until', \"it's\", 'while', 'aren', 'after', 'should', 'no', 'ourselves', 'him', 'me', 'below', 'same', 'here', 'yourselves', \"hadn't\", 'didn', \"haven't\", 'herself', 'again', 'you', 'doing', 'them', 'needn', 'in', 'then', \"didn't\", 'himself', 'mightn', 'would', \"you've\", 'both', 'doesn', 'itself', \"won't\", 'now', 'and', 'isn', 'of', 'did', 'why', 'other', \"weren't\", 'than', 'into', 'each', 'wasn', 'above', 'will', 'whom', 'these', 'had', 'an', 'too', 'what', 'such', 'between', 'by', 'our', 'those', 'being', 'hers', 'off', 'mustn', 'loved', \"couldn't\", 'against', 'weren', \"you'd\", 'she', 'there', \"you'll\", 'is', 'm', \"hasn't\", 'before', 'yours', \"aren't\", 'but', 'any', 'the', 'ain', 'love', 'nor', 'my', 'hadn', 'wouldn', 'their', 'only', 't', 'over', 'hasn', 'yourself', 'o', \"she's\", 'it', 'couldn', 'further'}\n"
     ]
    }
   ],
   "source": [
    "# adding more stop words\n",
    "\n",
    "stops.add(\"like\")\n",
    "stops.add(\"love\")\n",
    "stops.add(\"loved\")\n",
    "stops.add(\"loves\")\n",
    "stops.add(\"use\")\n",
    "stops.add(\"get\")\n",
    "stops.add(\"used\")\n",
    "stops.add(\"would\")\n",
    "stops.add(\"even\")\n",
    "\n",
    "print(stops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "66bd5962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 'purchased', 'needed', 'replacements', 'last', 'year', 'never', 'even', 'thought', 'using']\n"
     ]
    }
   ],
   "source": [
    "filtered = [[w for w in text if not w.lower() in stops] for text in tokenized_texts]\n",
    "\n",
    "print(filtered[0][:10])\n",
    "\n",
    "dictionary = Dictionary(filtered)\n",
    "# A corpus is a sparse datastore containing the number of times each word appears in each document.\n",
    "corpus = [dictionary.doc2bow(text) for text in filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8db61c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.LdaMulticore(corpus, id2word=dictionary, num_topics=5, workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6b8526f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  even first made water review back bought time one product\n",
      "1:  one recommend nice well good Great price quality product great\n",
      "2:  room little bed really good size color nice great well\n",
      "3:  well hot make great time easy clean one water coffee\n",
      "4:  really time little loved bought well plastic nice gift one\n"
     ]
    }
   ],
   "source": [
    "for ix in range(5):\n",
    "  top10 = np.argsort(model.get_topics()[ix])[-10:]\n",
    "  print(f'{ix}:  {\" \".join([dictionary[index] for index in top10])}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23445291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umass:  -2.7897077881587515\n",
      "c_v:  0.49743116895472317\n"
     ]
    }
   ],
   "source": [
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"umass: \", coherence)\n",
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='c_v')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"c_v: \", coherence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2e11d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with more topics\n",
    "\n",
    "model = models.LdaMulticore(corpus, id2word=dictionary, num_topics=15, workers=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b6a0958f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  years money got first time worked well one Works great\n",
      "1:  normal one hook B link made great product well works\n",
      "2:  made price blanket months good much tea better quality one\n",
      "3:  clock one lid little back time top mattress pillow water\n",
      "4:  bags Great bag one fit plastic little ice sheets great\n",
      "5:  put great one easy space good well wall small room\n",
      "6:  stick oven make easy great size one perfect pan well\n",
      "7:  advertised wanted needed Exactly great wine exactly fan described expected\n",
      "8:  value video quality job stainless images good steel rice Good\n",
      "9:  item review received price great bought one good gift product\n",
      "10:  cups pot machine mug one time hot water cup coffee\n",
      "11:  time really together looks put back arrived came box one\n",
      "12:  clean cutting kitchen well candles easy sharp cut knife one\n",
      "13:  well Perfect looks price color easy great nice Great quality\n",
      "14:  good much air really vacuum bought great well one bed\n"
     ]
    }
   ],
   "source": [
    "for ix in range(15):\n",
    "  top10 = np.argsort(model.get_topics()[ix])[-10:]\n",
    "  print(f'{ix}:  {\" \".join([dictionary[index] for index in top10])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fea7f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umass:  -3.1115238483793397\n",
      "c_v:  0.5395996969824143\n"
     ]
    }
   ],
   "source": [
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"umass: \", coherence)\n",
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='c_v')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"c_v: \", coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "394d51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with 7 topics\n",
    "\n",
    "model = models.LdaMulticore(corpus, id2word=dictionary, num_topics=7, workers=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19464802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  easy bottle one ice keep time mug cold hot water\n",
      "1:  buy Amazon return review first back received time product one\n",
      "2:  beautiful made look Great great well looks quality color nice\n",
      "3:  Good size Great perfect product well price quality good great\n",
      "4:  easy one small fit together well bed great pillow put\n",
      "5:  little much well great clean vacuum cup water one coffee\n",
      "6:  got happy Christmas daughter bought loved loves great gift one\n"
     ]
    }
   ],
   "source": [
    "for ix in range(7):\n",
    "  top10 = np.argsort(model.get_topics()[ix])[-10:]\n",
    "  print(f'{ix}:  {\" \".join([dictionary[index] for index in top10])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7cacc8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umass:  -2.9591023456669348\n",
      "c_v:  0.5076300451521149\n"
     ]
    }
   ],
   "source": [
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"umass: \", coherence)\n",
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='c_v')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"c_v: \", coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ebc9b3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  room great little one nice mattress soft quality bed color\n",
      "1:  looks put nice easy great price product well quality good\n",
      "2:  well first item even bought product made time great one\n",
      "3:  works little perfect gift size nice Great one well great\n",
      "4:  long Great good clean buy time easy water one product\n",
      "5:  lid easy really water cup one great hot time coffee\n",
      "umass:  -2.865590151866151\n",
      "c_v:  0.4880078954538149\n"
     ]
    }
   ],
   "source": [
    "model = models.LdaMulticore(corpus, id2word=dictionary, num_topics=6, workers=20)\n",
    "\n",
    "for ix in range(6):\n",
    "  top10 = np.argsort(model.get_topics()[ix])[-10:]\n",
    "  print(f'{ix}:  {\" \".join([dictionary[index] for index in top10])}')\n",
    "\n",
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"umass: \", coherence)\n",
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='c_v')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"c_v: \", coherence)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "969898f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  back new years well first two bought great time one\n",
      "1:  little quality size put really looks good well nice great\n",
      "2:  loves good one coffee price gift Great great quality product\n",
      "3:  pillow water clean make well time great one good easy\n",
      "umass:  -2.7666976895216795\n",
      "c_v:  0.4649223737707175\n"
     ]
    }
   ],
   "source": [
    "model = models.LdaMulticore(corpus, id2word=dictionary, num_topics=4, workers=20)\n",
    "\n",
    "for ix in range(4):\n",
    "  top10 = np.argsort(model.get_topics()[ix])[-10:]\n",
    "  print(f'{ix}:  {\" \".join([dictionary[index] for index in top10])}')\n",
    "\n",
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"umass: \", coherence)\n",
    "cm = CoherenceModel(model=model, texts=filtered, dictionary=dictionary, coherence='c_v')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"c_v: \", coherence)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8685473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
